{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from torch import nn\n",
    "import time\n",
    "\n",
    "def dft_conv(imgR,imgIm,kernelR,kernelIm):\n",
    "\n",
    "    # Fast complex multiplication\n",
    "    print(kernelR.shape, imgR.shape)\n",
    "    ac = torch.mul(kernelR, imgR)\n",
    "    bd = torch.mul(kernelIm, imgIm)\n",
    "    \n",
    "    ab_cd = torch.mul(torch.add(kernelR, kernelIm), torch.add(imgR, imgIm))\n",
    "    # print(ab_cd.sum(1)[0,0,:,:])\n",
    "    imgsR = ac - bd\n",
    "    imgsIm = ab_cd - ac - bd\n",
    "\n",
    "    # Sum over in channels\n",
    "    imgsR = imgsR.sum(1)\n",
    "    imgsIm = imgsIm.sum(1)\n",
    "\n",
    "\n",
    "    return imgsR,imgsIm\n",
    "\n",
    "class FFT_Conv_Layer(nn.Module):\n",
    "\n",
    "    def __init__(self,imgSize,inCs,outCs,imagDim,filtSize,cuda=False):\n",
    "\n",
    "        super(FFT_Conv_Layer, self).__init__()\n",
    "        self.filts = np.random.normal(0,0.01,(1,inCs,outCs,filtSize,filtSize,imagDim))\n",
    "        self.imgSize = imgSize\n",
    "        self.filtSize = np.size(self.filts,4)\n",
    "\n",
    "        if cuda:\n",
    "            self.filts = torch.from_numpy(self.filts).type(torch.float32).cuda()\n",
    "            self.filts = Parameter(self.filts)\n",
    "        \n",
    "\n",
    "    def forward(self,imgs):\n",
    "\n",
    "        # Pad and transform the image\n",
    "        # Pad arg = (last dim pad left side, last dim pad right side, 2nd last dim left side, etc..)\n",
    "        # imgs = torch.randn(batchSize,inCs,1,imgSize, imgSize,imagDim).cuda()\n",
    "        imgs = imgs.unsqueeze(2)\n",
    "        imgs = imgs.unsqueeze(5)\n",
    "        print()\n",
    "\n",
    "        imgs = F.pad(imgs, (0, 0, 0, self.filtSize - 1, 0,self.filtSize - 1))\n",
    "        imgs = imgs.squeeze(5)\n",
    "\n",
    "        imgs = torch.rfft(imgs,2,onesided= False)\n",
    "        # print(imgs.shape)\n",
    "\n",
    "        # Extract the real and imaginary parts\n",
    "        imgsR = imgs[:, :, :, :, :, 0]\n",
    "        imgsIm = imgs[:, :, :, :, :, 1]\n",
    "        \n",
    "\n",
    "        # Pad and transform the filters\n",
    "        filts = F.pad(self.filts, (0, 0, 0, self.imgSize - 1, 0, self.imgSize - 1))\n",
    "\n",
    "        filts = torch.fft(filts, 2)\n",
    "\n",
    "        # Extract the real and imaginary parts\n",
    "        filtR = filts[:, :, :, :, :, 0]\n",
    "        filtIm = filts[:, :, :, :, :, 1]\n",
    "\n",
    "        # Do element wise complex multiplication\n",
    "        imgsR, imgsIm = dft_conv(imgsR,imgsIm,filtR,filtIm)\n",
    "\n",
    "        # Add dim to concat over\n",
    "        imgsR = imgsR.unsqueeze(4)\n",
    "        imgsIm = imgsIm.unsqueeze(4)\n",
    "\n",
    "        # Concat the real and imaginary again then IFFT\n",
    "        imgs = torch.cat((imgsR,imgsIm),-1)\n",
    "        #print(\"1\",imgs.shape)\n",
    "        imgs = torch.ifft(imgs,2)\n",
    "        #print(\"2\",imgs.shape)\n",
    "\n",
    "        # Filter and imgs were real so imag should be ~0\n",
    "        imgs = imgs[:,:,1:-1,1:-1,0]\n",
    "        #print(\"3\",imgs.shape)\n",
    "\n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data agumentaiton'''\n",
    "traindir ='../data/train/'\n",
    "testdir = '../data/test/'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((256,256)),             \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    testdir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = torch.ones([1,3,224,224])\n",
    "# x = FFT_Conv_Layer(imgSize = 224 ,inCs = 3,outCs = 32,imagDim =2,filtSize = 3,cuda=True)\n",
    "# x(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=16, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset,batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "def trainStep(network, criterion, optimizer, X, y):\n",
    "\t\"\"\"\n",
    "\tOne training step of the network: forward prop + backprop + update parameters\n",
    "\tReturn: (loss, accuracy) of current batch\n",
    "\t\"\"\"\n",
    "\toptimizer.zero_grad()\n",
    "\toutputs = network(X)\n",
    "\tloss = criterion(outputs, y)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\taccuracy = float(torch.sum(torch.argmax(outputs, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn np.mean(loss), accuracy\n",
    "\n",
    "def getLossAccuracyOnDataset(network, dataset_loader, fast_device, criterion=None):\n",
    "\t\"\"\"\n",
    "\tReturns (loss, accuracy) of network on given dataset\n",
    "\t\"\"\"\n",
    "\tnetwork.is_training = False\n",
    "\taccuracy = 0.0\n",
    "\tloss = 0.0\n",
    "\tdataset_size = 0\n",
    "\tfor j, D in enumerate(dataset_loader, 0):\n",
    "\t\tX, y = D\n",
    "\t\tX = X.to(fast_device)\n",
    "\t\ty = y.to(fast_device)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tpred = network(X)\n",
    "\t\t\tif criterion is not None:\n",
    "\t\t\t\tloss += criterion(pred, y) * y.shape[0]\n",
    "\t\t\taccuracy += torch.sum(torch.argmax(pred, dim=1) == y).item()\n",
    "\t\tdataset_size += y.shape[0]\n",
    "\tloss, accuracy = loss / dataset_size, accuracy / dataset_size\n",
    "\tnetwork.is_training = True\n",
    "\treturn loss, accuracy\n",
    "\n",
    "def trainTeacherOnHparam(teacher_net, hparam, num_epochs, \n",
    "\t\t\t\t\t\ttrain_loader, val_loader, \n",
    "\t\t\t\t\t\tprint_every=0, \n",
    "\t\t\t\t\t\tfast_device=torch.device('cpu')):\n",
    "\t\"\"\"\n",
    "\tTrains teacher on given hyperparameters for given number of epochs; Pass val_loader=None when not required to validate for every epoch \n",
    "\tReturn: List of training loss, accuracy for each update calculated only on the batch; List of validation loss, accuracy for each epoch\n",
    "\t\"\"\"\n",
    "\ttrain_loss_list, train_acc_list, val_loss_list, val_acc_list = [], [], [], []\n",
    "\ttrain_losses = []\n",
    "\ttrain_acces = []\n",
    "\tteacher_net.dropout_input = hparam['dropout_input']\n",
    "\tteacher_net.dropout_hidden = hparam['dropout_hidden']\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\toptimizer = optim.SGD(teacher_net.parameters(), lr=hparam['lr'], momentum=hparam['momentum'], weight_decay=hparam['weight_decay'])\n",
    "\tlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=hparam['lr_decay'])\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tlr_scheduler.step()\n",
    "\t\tif epoch == 0:\n",
    "\t\t\tif val_loader is not None:\n",
    "\t\t\t\tval_loss, val_acc = getLossAccuracyOnDataset(teacher_net, val_loader, fast_device, criterion)\n",
    "\t\t\t\tval_loss_list.append(val_loss)\n",
    "\t\t\t\tval_acc_list.append(val_acc)\n",
    "\t\t\t\tprint('epoch: %d validation loss: %.3f validation accuracy: %.3f' %(epoch, val_loss, val_acc))\n",
    "\t\tfor i, data in enumerate(train_loader, 0):\n",
    "\t\t\tX, y = data\n",
    "\t\t\tX, y = X.to(fast_device), y.to(fast_device)\n",
    "\t\t\tloss, acc = trainStep(teacher_net, criterion, optimizer, X, y)\n",
    "\t\t\ttrain_loss_list.append(loss)\n",
    "\t\t\ttrain_acc_list.append(acc)\n",
    "\n",
    "\t\t\tif print_every > 0 and i % print_every == print_every - 1:\n",
    "\t\t\t\tprint('[%d, %5d/%5d] train loss: %.3f train accuracy: %.3f' %\n",
    "\t\t\t\t\t  (epoch + 1, i + 1, len(train_loader), loss, acc))\n",
    "\t\ttrain_acces.append(np.mean(train_acc_list))\n",
    "\t\ttrain_losses.append(np.mean(train_acc_list))\t\n",
    "\t\tif val_loader is not None:\n",
    "\t\t\tval_loss, val_acc = getLossAccuracyOnDataset(teacher_net, val_loader, fast_device, criterion)\n",
    "\t\t\tval_loss_list.append(val_loss)\n",
    "\t\t\tval_acc_list.append(val_acc)\n",
    "\t\t\tprint('epoch: %d validation loss: %.3f validation accuracy: %.3f' %(epoch + 1, val_loss, val_acc))\n",
    "\treturn {'train_loss': train_losses, \n",
    "\t\t\t'train_acc': train_acces}\n",
    "\n",
    "def studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha):\n",
    "\t\"\"\"\n",
    "\tOne training step of student network: forward prop + backprop + update parameters\n",
    "\tReturn: (loss, accuracy) of current batch\n",
    "\t\"\"\"\n",
    "\toptimizer.zero_grad()\n",
    "\tteacher_pred = None\n",
    "\tif (alpha > 0):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tteacher_pred = teacher_net(X) \n",
    "\tstudent_pred = student_net(X)\n",
    "\t# print(student_pred)\n",
    "\tloss = studentLossFn(teacher_pred, student_pred, y, T, alpha)\n",
    "\tloss.backward()\n",
    "\ttorch.nn.utils.clip_grad_norm_(student_net.parameters(), 20)\n",
    "\toptimizer.step()\n",
    "\taccuracy = float(torch.sum(torch.argmax(student_pred, dim=1) == y).item()) / y.shape[0]\n",
    "\treturn loss, accuracy\n",
    "\n",
    "def trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
    "\t\t\t\t\t\ttrain_loader, val_loader, \n",
    "\t\t\t\t\t\tprint_every=0, \n",
    "\t\t\t\t\t\tfast_device=torch.device('cpu')):\n",
    "\t\"\"\"\n",
    "\tTrains teacher on given hyperparameters for given number of epochs; Pass val_loader=None when not required to validate for every epoch\n",
    "\tReturn: List of training loss, accuracy for each update calculated only on the batch; List of validation loss, accuracy for each epoch\n",
    "\t\"\"\"\n",
    "\ttrain_loss_list, train_acc_list, val_acc_list = [], [], []\n",
    "\tT = hparam['T']\n",
    "\talpha = hparam['alpha']\n",
    "\tstudent_net.dropout_input = hparam['dropout_input']\n",
    "\tstudent_net.dropout_hidden = hparam['dropout_hidden']\n",
    "\toptimizer = optim.SGD(student_net.parameters(), lr=hparam['lr'], momentum=hparam['momentum'], weight_decay=hparam['weight_decay'])\n",
    "\tlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=hparam['lr_decay'])\n",
    "\tBASE_PATH = '/gdrive/My Drive/colab_files/caifar10_alexnet/'\n",
    "\n",
    "\tdef studentLossFn(teacher_pred, student_pred, y, T, alpha):\n",
    "\t\t\"\"\"\n",
    "\t\tLoss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
    "\t\tReturn: loss\n",
    "\t\t\"\"\"\n",
    "\t\tif (alpha > 0):\n",
    "\t\t\tloss = F.kl_div(F.log_softmax(student_pred / T, dim=1), F.softmax(teacher_pred / T, dim=1), reduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
    "\t\telse:\n",
    "\t\t\tloss = F.cross_entropy(student_pred, y)\n",
    "\t\treturn loss\n",
    "\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tlr_scheduler.step()\n",
    "\t\tepoch_loss = 0\n",
    "\n",
    "\t\tif epoch == 0:\n",
    "\t\t\tif val_loader is not None:\n",
    "\t\t\t\t_, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
    "\t\t\t\tval_acc_list.append(val_acc)\n",
    "\t\t\t\tprint('epoch: %d validation accuracy: %.3f' %(epoch, val_acc))\n",
    "\t\tfor i, batch in enumerate(train_loader, 0):\n",
    "\t\t\timgs = batch['image']\n",
    "\t\t\ttrue_masks = batch['mask']\n",
    "\t\t\tassert imgs.shape[1] == net.n_channels, \\\n",
    "\t\t\t\t\tf'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "\t\t\t\t\tf'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
    "\t\t\t\t\t'the images are loaded correctly.'\n",
    "\n",
    "\t\t\timgs = imgs.to(device=device, dtype=torch.float32)\n",
    "\t\t\tmask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
    "\t\t\ttrue_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "\t\t\tmasks_pred = net(imgs)\n",
    "\t\t\tloss = criterion(masks_pred, true_masks)\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tnn.utils.clip_grad_value_(net.parameters(), 20)\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t# X, y = data\n",
    "\t\t\t# X, y = X.to(fast_device), y.to(fast_device)\n",
    "\t\t\t# loss, acc = studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha)\n",
    "\t\t\ttrain_loss_list.append(loss)\n",
    "\t\t\ttrain_acc_list.append(acc)\n",
    "\t\t\tif print_every > 0 and i % print_every == print_every - 1:\n",
    "\t\t\t  print('[%d, %5d/%5d] train loss: %.3f train accuracy: %.3f' %\n",
    "\t\t\t    (epoch + 1, i + 1, len(train_loader), loss, acc))\n",
    "\t\n",
    "\t\tif val_loader is not None:\n",
    "\t\t\t_, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
    "\t\t\tval_acc_list.append(val_acc)\n",
    "\t\t\tprint('epoch: %d validation accuracy: %.3f' %(epoch + 1, val_acc))\n",
    "\t\n",
    "\treturn {'train_loss': train_loss_list, \n",
    "\t\t\t'train_acc': train_acc_list, \n",
    "\t\t\t'val_acc': val_acc_list}\n",
    "\n",
    "def hparamToString(hparam):\n",
    "\t\"\"\"\n",
    "\tConvert hparam dictionary to string with deterministic order of attribute of hparam in output string\n",
    "\t\"\"\"\n",
    "\thparam_str = ''\n",
    "\tfor k, v in sorted(hparam.items()):\n",
    "\t\thparam_str += k + '=' + str(v) + ', '\n",
    "\treturn hparam_str[:-2]\n",
    "\n",
    "def hparamDictToTuple(hparam):\n",
    "\t\"\"\"\n",
    "\tConvert hparam dictionary to tuple with deterministic order of attribute of hparam in output tuple\n",
    "\t\"\"\"\n",
    "\thparam_tuple = [v for k, v in sorted(hparam.items())]\n",
    "\treturn tuple(hparam_tuple)\n",
    "\n",
    "def getTrainMetricPerEpoch(train_metric, updates_per_epoch):\n",
    "\t\"\"\"\n",
    "\tSmooth the training metric calculated for each batch of training set by averaging over batches in an epoch\n",
    "\tInput: List of training metric calculated for each batch\n",
    "\tOutput: List of training matric averaged over each epoch\n",
    "\t\"\"\"\n",
    "\ttrain_metric_per_epoch = []\n",
    "\ttemp_sum = 0.0\n",
    "\tfor i in range(len(train_metric)):\n",
    "\t\ttemp_sum += train_metric[i]\n",
    "\t\tif (i % updates_per_epoch == updates_per_epoch - 1):\n",
    "\t\t\ttrain_metric_per_epoch.append(temp_sum / updates_per_epoch)\n",
    "\t\t\ttemp_sum = 0.0\n",
    "\n",
    "\treturn train_metric_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(9216, 512)),\n",
    "                          ('relu1', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(512,256)),\n",
    "                          ('relu2', nn.ReLU()),\n",
    "                          ('fc3', nn.Linear(256, 1)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.add_module(\"classifier\",classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.fc1.weight\n",
      "classifier.fc1.bias\n",
      "classifier.fc2.weight\n",
      "classifier.fc2.bias\n",
      "classifier.fc3.weight\n",
      "classifier.fc3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "          print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=9216, out_features=512, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (output): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4036, device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2487179/2853318252.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "#model = StudentNetwork_noRelu()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "model.to(device)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "traininglosses = []\n",
    "testinglosses = []\n",
    "testaccuracy = []\n",
    "totalsteps = []\n",
    "epochs =1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps = model(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    \n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            \n",
    "            traininglosses.append(running_loss/print_every)\n",
    "            testinglosses.append(test_loss/len(testloader))\n",
    "            testaccuracy.append(accuracy/len(testloader))\n",
    "            totalsteps.append(steps)\n",
    "            print(f\"Device {device}..\"\n",
    "                  f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Step {steps}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pythorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
