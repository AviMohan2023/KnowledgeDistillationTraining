{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "onn_kd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT1IcancONXI"
      },
      "source": [
        "#   0 enviorment and data setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PNfYt3Vxu2c"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDxdbqokQk1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d812a571-7d06-41d0-a705-8d4156287ae6"
      },
      "source": [
        "'''location for data'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_PATH = '/content/drive/My Drive/high10'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH7ci2ERx74k"
      },
      "source": [
        "import os\n",
        "if not os.path.exists('/content/train'):\n",
        "  !tar --exclude='._*' -xvf /content/drive/My\\ Drive/high10/hightrain.tar\n",
        "if not os.path.exists('/content/test'):\n",
        "  !tar --exclude='._*' -xvf /content/drive/My\\ Drive/high10/hightest.tar\n",
        "if os.path.exists('/content/test') & os.path.exists('/content/train'):\n",
        "  print(\"all done\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqm_TPwvPCg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1041e9be-52f8-44af-8897-a83f6dcf1b72"
      },
      "source": [
        "import os\n",
        "data_path = '/content'\n",
        "traindir = os.path.join(data_path + '/train')\n",
        "print(traindir)\n",
        "testdir = os.path.join(data_path + '/test')\n",
        "print(testdir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/train\n",
            "/content/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYQLEzZWUsxg"
      },
      "source": [
        "'''data agumentaiton'''\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    traindir,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((256,256)),             \n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    testdir,\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24pTyLEGU9GX"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=16, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset,batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpTvFLx0OWIm"
      },
      "source": [
        "# 1 utils setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWl4DkJopJ0j"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "def trainStep(network, criterion, optimizer, X, y):\n",
        "\t\"\"\"\n",
        "\tOne training step of the network: forward prop + backprop + update parameters\n",
        "\tReturn: (loss, accuracy) of current batch\n",
        "\t\"\"\"\n",
        "\toptimizer.zero_grad()\n",
        "\toutputs = network(X)\n",
        "\tloss = criterion(outputs, y)\n",
        "\tloss.backward()\n",
        "\toptimizer.step()\n",
        "\taccuracy = float(torch.sum(torch.argmax(outputs, dim=1) == y).item()) / y.shape[0]\n",
        "\treturn np.mean(loss), accuracy\n",
        "\n",
        "def getLossAccuracyOnDataset(network, dataset_loader, fast_device, criterion=None):\n",
        "\t\"\"\"\n",
        "\tReturns (loss, accuracy) of network on given dataset\n",
        "\t\"\"\"\n",
        "\tnetwork.is_training = False\n",
        "\taccuracy = 0.0\n",
        "\tloss = 0.0\n",
        "\tdataset_size = 0\n",
        "\tfor j, D in enumerate(dataset_loader, 0):\n",
        "\t\tX, y = D\n",
        "\t\tX = X.to(fast_device)\n",
        "\t\ty = y.to(fast_device)\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tpred = network(X)\n",
        "\t\t\tif criterion is not None:\n",
        "\t\t\t\tloss += criterion(pred, y) * y.shape[0]\n",
        "\t\t\taccuracy += torch.sum(torch.argmax(pred, dim=1) == y).item()\n",
        "\t\tdataset_size += y.shape[0]\n",
        "\tloss, accuracy = loss / dataset_size, accuracy / dataset_size\n",
        "\tnetwork.is_training = True\n",
        "\treturn loss, accuracy\n",
        "\n",
        "def trainTeacherOnHparam(teacher_net, hparam, num_epochs, \n",
        "\t\t\t\t\t\ttrain_loader, val_loader, \n",
        "\t\t\t\t\t\tprint_every=0, \n",
        "\t\t\t\t\t\tfast_device=torch.device('cpu')):\n",
        "\t\"\"\"\n",
        "\tTrains teacher on given hyperparameters for given number of epochs; Pass val_loader=None when not required to validate for every epoch \n",
        "\tReturn: List of training loss, accuracy for each update calculated only on the batch; List of validation loss, accuracy for each epoch\n",
        "\t\"\"\"\n",
        "\ttrain_loss_list, train_acc_list, val_loss_list, val_acc_list = [], [], [], []\n",
        "\ttrain_losses = []\n",
        "\ttrain_acces = []\n",
        "\tteacher_net.dropout_input = hparam['dropout_input']\n",
        "\tteacher_net.dropout_hidden = hparam['dropout_hidden']\n",
        "\tcriterion = nn.CrossEntropyLoss()\n",
        "\toptimizer = optim.SGD(teacher_net.parameters(), lr=hparam['lr'], momentum=hparam['momentum'], weight_decay=hparam['weight_decay'])\n",
        "\tlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=hparam['lr_decay'])\n",
        "\tfor epoch in range(num_epochs):\n",
        "\t\tlr_scheduler.step()\n",
        "\t\tif epoch == 0:\n",
        "\t\t\tif val_loader is not None:\n",
        "\t\t\t\tval_loss, val_acc = getLossAccuracyOnDataset(teacher_net, val_loader, fast_device, criterion)\n",
        "\t\t\t\tval_loss_list.append(val_loss)\n",
        "\t\t\t\tval_acc_list.append(val_acc)\n",
        "\t\t\t\tprint('epoch: %d validation loss: %.3f validation accuracy: %.3f' %(epoch, val_loss, val_acc))\n",
        "\t\tfor i, data in enumerate(train_loader, 0):\n",
        "\t\t\tX, y = data\n",
        "\t\t\tX, y = X.to(fast_device), y.to(fast_device)\n",
        "\t\t\tloss, acc = trainStep(teacher_net, criterion, optimizer, X, y)\n",
        "\t\t\ttrain_loss_list.append(loss)\n",
        "\t\t\ttrain_acc_list.append(acc)\n",
        "\n",
        "\t\t\tif print_every > 0 and i % print_every == print_every - 1:\n",
        "\t\t\t\tprint('[%d, %5d/%5d] train loss: %.3f train accuracy: %.3f' %\n",
        "\t\t\t\t\t  (epoch + 1, i + 1, len(train_loader), loss, acc))\n",
        "\t\ttrain_acces.append(np.mean(train_acc_list))\n",
        "\t\ttrain_losses.append(np.mean(train_acc_list))\t\n",
        "\t\tif val_loader is not None:\n",
        "\t\t\tval_loss, val_acc = getLossAccuracyOnDataset(teacher_net, val_loader, fast_device, criterion)\n",
        "\t\t\tval_loss_list.append(val_loss)\n",
        "\t\t\tval_acc_list.append(val_acc)\n",
        "\t\t\tprint('epoch: %d validation loss: %.3f validation accuracy: %.3f' %(epoch + 1, val_loss, val_acc))\n",
        "\treturn {'train_loss': train_losses, \n",
        "\t\t\t'train_acc': train_acces}\n",
        "\n",
        "def studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha):\n",
        "\t\"\"\"\n",
        "\tOne training step of student network: forward prop + backprop + update parameters\n",
        "\tReturn: (loss, accuracy) of current batch\n",
        "\t\"\"\"\n",
        "\toptimizer.zero_grad()\n",
        "\tteacher_pred = None\n",
        "\tif (alpha > 0):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tteacher_pred = teacher_net(X) \n",
        "\tstudent_pred = student_net(X)\n",
        "\t# print(student_pred)\n",
        "\tloss = studentLossFn(teacher_pred, student_pred, y, T, alpha)\n",
        "\tloss.backward()\n",
        "\ttorch.nn.utils.clip_grad_norm_(student_net.parameters(), 20)\n",
        "\toptimizer.step()\n",
        "\taccuracy = float(torch.sum(torch.argmax(student_pred, dim=1) == y).item()) / y.shape[0]\n",
        "\treturn loss, accuracy\n",
        "\n",
        "def trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n",
        "\t\t\t\t\t\ttrain_loader, val_loader, \n",
        "\t\t\t\t\t\tprint_every=0, \n",
        "\t\t\t\t\t\tfast_device=torch.device('cpu')):\n",
        "\t\"\"\"\n",
        "\tTrains teacher on given hyperparameters for given number of epochs; Pass val_loader=None when not required to validate for every epoch\n",
        "\tReturn: List of training loss, accuracy for each update calculated only on the batch; List of validation loss, accuracy for each epoch\n",
        "\t\"\"\"\n",
        "\ttrain_loss_list, train_acc_list, val_acc_list = [], [], []\n",
        "\tT = hparam['T']\n",
        "\talpha = hparam['alpha']\n",
        "\tstudent_net.dropout_input = hparam['dropout_input']\n",
        "\tstudent_net.dropout_hidden = hparam['dropout_hidden']\n",
        "\toptimizer = optim.SGD(student_net.parameters(), lr=hparam['lr'], momentum=hparam['momentum'], weight_decay=hparam['weight_decay'])\n",
        "\tlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=hparam['lr_decay'])\n",
        "\tBASE_PATH = '/gdrive/My Drive/colab_files/caifar10_alexnet/'\n",
        "\n",
        "\tdef studentLossFn(teacher_pred, student_pred, y, T, alpha):\n",
        "\t\t\"\"\"\n",
        "\t\tLoss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
        "\t\tReturn: loss\n",
        "\t\t\"\"\"\n",
        "\t\tif (alpha > 0):\n",
        "\t\t\tloss = F.kl_div(F.log_softmax(student_pred / T, dim=1), F.softmax(teacher_pred / T, dim=1), reduction='batchmean') * (T ** 2) * alpha + F.cross_entropy(student_pred, y) * (1 - alpha)\n",
        "\t\telse:\n",
        "\t\t\tloss = F.cross_entropy(student_pred, y)\n",
        "\t\treturn loss\n",
        "\n",
        "\tfor epoch in range(num_epochs):\n",
        "\t\tlr_scheduler.step()\n",
        "\t\tepoch_loss = 0\n",
        "\n",
        "\t\tif epoch == 0:\n",
        "\t\t\tif val_loader is not None:\n",
        "\t\t\t\t_, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
        "\t\t\t\tval_acc_list.append(val_acc)\n",
        "\t\t\t\tprint('epoch: %d validation accuracy: %.3f' %(epoch, val_acc))\n",
        "\t\tfor i, batch in enumerate(train_loader, 0):\n",
        "\t\t\timgs = batch['image']\n",
        "\t\t\ttrue_masks = batch['mask']\n",
        "\t\t\tassert imgs.shape[1] == net.n_channels, \\\n",
        "\t\t\t\t\tf'Network has been defined with {net.n_channels} input channels, ' \\\n",
        "\t\t\t\t\tf'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
        "\t\t\t\t\t'the images are loaded correctly.'\n",
        "\n",
        "\t\t\timgs = imgs.to(device=device, dtype=torch.float32)\n",
        "\t\t\tmask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
        "\t\t\ttrue_masks = true_masks.to(device=device, dtype=mask_type)\n",
        "\n",
        "\t\t\tmasks_pred = net(imgs)\n",
        "\t\t\tloss = criterion(masks_pred, true_masks)\n",
        "\t\t\tepoch_loss += loss.item()\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tloss.backward()\n",
        "\t\t\tnn.utils.clip_grad_value_(net.parameters(), 20)\n",
        "\t\t\toptimizer.step()\n",
        "\t\t\t# X, y = data\n",
        "\t\t\t# X, y = X.to(fast_device), y.to(fast_device)\n",
        "\t\t\t# loss, acc = studentTrainStep(teacher_net, student_net, studentLossFn, optimizer, X, y, T, alpha)\n",
        "\t\t\ttrain_loss_list.append(loss)\n",
        "\t\t\ttrain_acc_list.append(acc)\n",
        "\t\t\tif print_every > 0 and i % print_every == print_every - 1:\n",
        "\t\t\t  print('[%d, %5d/%5d] train loss: %.3f train accuracy: %.3f' %\n",
        "\t\t\t    (epoch + 1, i + 1, len(train_loader), loss, acc))\n",
        "\t\n",
        "\t\tif val_loader is not None:\n",
        "\t\t\t_, val_acc = getLossAccuracyOnDataset(student_net, val_loader, fast_device)\n",
        "\t\t\tval_acc_list.append(val_acc)\n",
        "\t\t\tprint('epoch: %d validation accuracy: %.3f' %(epoch + 1, val_acc))\n",
        "\t\n",
        "\treturn {'train_loss': train_loss_list, \n",
        "\t\t\t'train_acc': train_acc_list, \n",
        "\t\t\t'val_acc': val_acc_list}\n",
        "\n",
        "def hparamToString(hparam):\n",
        "\t\"\"\"\n",
        "\tConvert hparam dictionary to string with deterministic order of attribute of hparam in output string\n",
        "\t\"\"\"\n",
        "\thparam_str = ''\n",
        "\tfor k, v in sorted(hparam.items()):\n",
        "\t\thparam_str += k + '=' + str(v) + ', '\n",
        "\treturn hparam_str[:-2]\n",
        "\n",
        "def hparamDictToTuple(hparam):\n",
        "\t\"\"\"\n",
        "\tConvert hparam dictionary to tuple with deterministic order of attribute of hparam in output tuple\n",
        "\t\"\"\"\n",
        "\thparam_tuple = [v for k, v in sorted(hparam.items())]\n",
        "\treturn tuple(hparam_tuple)\n",
        "\n",
        "def getTrainMetricPerEpoch(train_metric, updates_per_epoch):\n",
        "\t\"\"\"\n",
        "\tSmooth the training metric calculated for each batch of training set by averaging over batches in an epoch\n",
        "\tInput: List of training metric calculated for each batch\n",
        "\tOutput: List of training matric averaged over each epoch\n",
        "\t\"\"\"\n",
        "\ttrain_metric_per_epoch = []\n",
        "\ttemp_sum = 0.0\n",
        "\tfor i in range(len(train_metric)):\n",
        "\t\ttemp_sum += train_metric[i]\n",
        "\t\tif (i % updates_per_epoch == updates_per_epoch - 1):\n",
        "\t\t\ttrain_metric_per_epoch.append(temp_sum / updates_per_epoch)\n",
        "\t\t\ttemp_sum = 0.0\n",
        "\n",
        "\treturn train_metric_per_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Ia0irMQid0"
      },
      "source": [
        "# 2 network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFX4kwrNyIqH"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class spectral_pool_layer(nn.Module):\n",
        "  def __init__(self,filter_size=3,freq_dropout_lower_bound=None,freq_dropout_upper_bound=None,train_phase = False ):\n",
        "    super(spectral_pool_layer,self).__init__()\n",
        "    # assert only 1 dimension passed for filter size\n",
        "    assert isinstance(filter_size, int)\n",
        "    # input_shape = x.shape\n",
        "    # assert len(input_shape) == 4\n",
        "    # _, _, H, W = input_shape\n",
        "    # assert H == W\n",
        "\n",
        "    self.filter_size = filter_size\n",
        "    self.freq_dropout_lower_bound = freq_dropout_lower_bound\n",
        "    self.freq_dropout_upper_bound = freq_dropout_upper_bound\n",
        "    self.activation = F\n",
        "    self.train_phase = train_phase \n",
        "  \n",
        "  def forward(self,x):\n",
        "    # Compute the Fourier transform of the image\n",
        "    im_fft = torch.rfft(x,2,onesided = False)\n",
        "\n",
        "    # Truncate the spectrum\n",
        "    im_transformed = self._common_spectral_pool(im_fft, self.filter_size)\n",
        "\n",
        "    if ( self.freq_dropout_lower_bound is not None and self.freq_dropout_upper_bound is not None):\n",
        "      def true_fn():\n",
        "      \t\ttf_random_cutoff = tf.random_uniform(\n",
        "\t\t\t\t\t\t[],\n",
        "\t\t\t\t\t\tfreq_dropout_lower_bound,\n",
        "\t\t\t\t\t\tfreq_dropout_upper_bound\n",
        "\t\t\t\t\t)\n",
        "      \t\tdropout_mask = _frequency_dropout_mask(\n",
        "\t\t\t\t\t\tfilter_size,\n",
        "\t\t\t\t\t\ttf_random_cutoff\n",
        "\t\t\t\t\t)\n",
        "      \t\treturn im_transformed * dropout_mask\n",
        "\n",
        "\t\t\t\t# In the testing phase, return the truncated frequency\n",
        "\t\t\t\t# matrix unchanged.\n",
        "      def false_fn():\n",
        "      \t\treturn im_transformed\n",
        "      im_downsampled = tf.cond(\n",
        "\t\t\t\t\tself.train_phase,\n",
        "\t\t\t\t\ttrue_fn=true_fn,\n",
        "\t\t\t\t\tfalse_fn=false_fn\n",
        "\t\t\t\t)\n",
        "      im_out = torch.irfft(im_downsampled,2, onesided=False)\n",
        "\t\t\n",
        "    else:\n",
        "      im_out = torch.irfft(im_transformed,2, onesided=False)\n",
        "    \n",
        "    if self.activation is not None:\n",
        "      \t\tcell_out = self.activation.relu(im_out)\n",
        "    else:\n",
        "      cell_out = im_out\n",
        "    return cell_out\n",
        "\n",
        "  def _common_spectral_pool(self,images, filter_size):\n",
        "    assert len(images.shape) == 5\n",
        "    assert filter_size >= 3\n",
        "\t\n",
        "    if filter_size % 2 == 1:\n",
        "      n = int((filter_size-1)/2)\n",
        "      top_left = images[:, :, :n+1, :n+1]\n",
        "      top_right = images[:, :, :n+1, -n:]\n",
        "      bottom_left = images[:, :, -n:, :n+1]\n",
        "      bottom_right = images[:, :, -n:, -n:]\n",
        "      top_combined = torch.cat([top_left, top_right], axis=-2)\n",
        "      # print(top_combined.shape)\n",
        "      bottom_combined = torch.cat([bottom_left, bottom_right], axis=-2)\n",
        "      # print(bottom_combined.shape)\n",
        "      all_together = torch.cat([top_combined, bottom_combined], axis=-3)\n",
        "      return all_together"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybA2NSHMtd0B"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from scipy import signal\n",
        "import scipy\n",
        "from torch import nn\n",
        "import time\n",
        "\n",
        "def dft_conv(imgR,imgIm,kernelR,kernelIm):\n",
        "\n",
        "    # Fast complex multiplication\n",
        "    ac = torch.mul(kernelR, imgR)\n",
        "    bd = torch.mul(kernelIm, imgIm)\n",
        "    \n",
        "    ab_cd = torch.mul(torch.add(kernelR, kernelIm), torch.add(imgR, imgIm))\n",
        "    # print(ab_cd.sum(1)[0,0,:,:])\n",
        "    imgsR = ac - bd\n",
        "    imgsIm = ab_cd - ac - bd\n",
        "\n",
        "    # Sum over in channels\n",
        "    imgsR = imgsR.sum(1)\n",
        "    imgsIm = imgsIm.sum(1)\n",
        "\n",
        "\n",
        "    return imgsR,imgsIm\n",
        "\n",
        "class FFT_Conv_Layer(nn.Module):\n",
        "\n",
        "    def __init__(self,imgSize,inCs,outCs,imagDim,filtSize,cuda=False):\n",
        "\n",
        "        super(FFT_Conv_Layer, self).__init__()\n",
        "        self.filts = np.random.normal(0,0.01,(1,inCs,outCs,filtSize,filtSize,imagDim))\n",
        "        self.imgSize = imgSize\n",
        "        self.filtSize = np.size(self.filts,4)\n",
        "\n",
        "        if cuda:\n",
        "            self.filts = torch.from_numpy(self.filts).type(torch.float32).cuda()\n",
        "            self.filts = Parameter(self.filts)\n",
        "        \n",
        "\n",
        "    def forward(self,imgs):\n",
        "\n",
        "        # Pad and transform the image\n",
        "        # Pad arg = (last dim pad left side, last dim pad right side, 2nd last dim left side, etc..)\n",
        "        # imgs = torch.randn(batchSize,inCs,1,imgSize, imgSize,imagDim).cuda()\n",
        "        imgs = imgs.unsqueeze(2)\n",
        "        imgs = imgs.unsqueeze(5)\n",
        "\n",
        "        imgs = F.pad(imgs, (0, 0, 0, self.filtSize - 1, 0,self.filtSize - 1))\n",
        "        imgs = imgs.squeeze(5)\n",
        "\n",
        "        imgs = torch.rfft(imgs,2,onesided= False)\n",
        "        # print(imgs.shape)\n",
        "\n",
        "        # Extract the real and imaginary parts\n",
        "        imgsR = imgs[:, :, :, :, :, 0]\n",
        "        imgsIm = imgs[:, :, :, :, :, 1]\n",
        "        \n",
        "\n",
        "        # Pad and transform the filters\n",
        "        filts = F.pad(self.filts, (0, 0, 0, self.imgSize - 1, 0, self.imgSize - 1))\n",
        "\n",
        "        filts = torch.fft(filts, 2)\n",
        "\n",
        "        # Extract the real and imaginary parts\n",
        "        filtR = filts[:, :, :, :, :, 0]\n",
        "        filtIm = filts[:, :, :, :, :, 1]\n",
        "\n",
        "        # Do element wise complex multiplication\n",
        "        imgsR, imgsIm = dft_conv(imgsR,imgsIm,filtR,filtIm)\n",
        "\n",
        "        # Add dim to concat over\n",
        "        imgsR = imgsR.unsqueeze(4)\n",
        "        imgsIm = imgsIm.unsqueeze(4)\n",
        "\n",
        "        # Concat the real and imaginary again then IFFT\n",
        "        imgs = torch.cat((imgsR,imgsIm),-1)\n",
        "        #print(\"1\",imgs.shape)\n",
        "        imgs = torch.ifft(imgs,2)\n",
        "        #print(\"2\",imgs.shape)\n",
        "\n",
        "        # Filter and imgs were real so imag should be ~0\n",
        "        imgs = imgs[:,:,1:-1,1:-1,0]\n",
        "        #print(\"3\",imgs.shape)\n",
        "\n",
        "        return imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoF-8TK8iJuG"
      },
      "source": [
        "class StudentNetwork_noRelu(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(StudentNetwork_noRelu,self).__init__()\n",
        "    self.conv1 = FFT_Conv_Layer(imgSize = 224 ,inCs = 3,outCs = 32,imagDim =2,filtSize = 3,cuda=True)\n",
        "    # self.conv1 = nn.Conv2d(3,64, kernel_size=11,stride = 4,padding = 2)\n",
        "    self.conv2 = FFT_Conv_Layer(imgSize = 113 ,inCs = 32,outCs =64,imagDim =2,filtSize = 3,cuda=True)\n",
        "    self.conv3 = FFT_Conv_Layer(imgSize = 27 ,inCs = 64,outCs = 256,imagDim =2,filtSize = 3,cuda=True)\n",
        "    self.fc1 = nn.Linear(9216, 512)\n",
        "    self.fc2 = nn.Linear(512,256)\n",
        "    self.fc3 = nn.Linear(256,10)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "    self.dropout_input = 0.5\n",
        "    self.dropout_hidden = 0.5\n",
        "    self.is_training = True\n",
        "    self.avepool = nn.AdaptiveAvgPool2d((6,6))\n",
        "    self.m = nn.LogSoftmax(dim=1)\n",
        "    self.max_113 = spectral_pool_layer(113)\n",
        "    self.max_27 = spectral_pool_layer(27)\n",
        "\n",
        "    \n",
        "  \n",
        "  def forward(self,x):\n",
        "    #print(x.shape)\n",
        "    forw = self.conv1(x)\n",
        "    # print(forw.shape)\n",
        "    #forw = self.max_113(torch.square(self.conv1(x)))\n",
        "    #forw = self.max_27(torch.square(self.conv2(forw)))\n",
        "    forw = self.max_113(self.conv1(x))\n",
        "    forw = self.max_27(self.conv2(forw))\n",
        "    # # print(forw.shape)\n",
        "    forw = self.conv3(forw)\n",
        "    # # print(forw.shape)\n",
        "    forw = self.maxpool(forw)\n",
        "    forw = self.avepool(forw)\n",
        "    forw = forw.view(-1,9216)\n",
        "    forw = F.dropout(forw, p=self.dropout_input, training=self.is_training)\n",
        "    forw = F.dropout(self.fc1(forw), p=self.dropout_hidden, training=self.is_training)\n",
        "    forw = F.relu(forw)\n",
        "    forw = self.fc2(forw)\n",
        "    forw = F.relu(forw)\n",
        "    forw = self.fc3(forw)\n",
        "    return self.m(forw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ze84YBQOWE_"
      },
      "source": [
        "time test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNKh9RnHOVNQ",
        "outputId": "b3ffccae-a63d-43c5-dc9a-f2b9f5b6e0df"
      },
      "source": [
        "inputs = torch.rand([1,3,224,224],dtype= torch.float)\n",
        "print(inputs.shape)\n",
        "inputs = inputs.to(\"cuda\")\n",
        "model = StudentNetwork_noRelu()\n",
        "model.to('cuda')\n",
        "\n",
        "\n",
        "import datetime\n",
        "starttime = datetime.datetime.now()\n",
        "#long running\n",
        "for i in range(100):\n",
        "  model.forward(inputs)\n",
        "\n",
        "endtime = datetime.datetime.now()\n",
        "print (endtime - starttime)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 224, 224])\n",
            "0:00:04.546426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4NgeFHLQqSy"
      },
      "source": [
        "# 3 pre-training for students "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxtJKLh1WIXD"
      },
      "source": [
        "device = 'cuda'\n",
        "model = StudentNetwork_noRelu()\n",
        "# model = teacher_net\n",
        "criterion = nn.NLLLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "model.to(device)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "traininglosses = []\n",
        "testinglosses = []\n",
        "testaccuracy = []\n",
        "totalsteps = []\n",
        "epochs = 50\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 100\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "        # Move input and label tensors to the default device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        print(inputs.shape)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    \n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    # Calculate accuracy\n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "            \n",
        "            traininglosses.append(running_loss/print_every)\n",
        "            testinglosses.append(test_loss/len(testloader))\n",
        "            testaccuracy.append(accuracy/len(testloader))\n",
        "            totalsteps.append(steps)\n",
        "            print(f\"Device {device}..\"\n",
        "                  f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                  f\"Step {steps}.. \"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG6UCuJ7QzZT"
      },
      "source": [
        "# 4 load the pretrain student model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O4DGU5ycaRt"
      },
      "source": [
        "import torch\n",
        "pretrained_dict = torch.load(BASE_PATH+'/net_params.pkl')\n",
        "net = StudentNetwork_noRelu()\n",
        "net.load_state_dict(pretrained_dict) \n",
        "device = \"cuda\"\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSi4n2jdesBE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e305339b-d395-46a5-da90-a95240aea005"
      },
      "source": [
        "_, test_accuracy = getLossAccuracyOnDataset(net, testloader, device)\n",
        "print('teacher test accuracy (w distillation): ', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "teacher test accuracy (w distillation):  0.7272727272727273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j5qzq8ugo9U"
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "  if (\"conv\" in name):\n",
        "    param.requires_grad = False\n",
        "  else:\n",
        "    param.requires_grad = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttWJgbo-qa4Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4ed611fa-fdb9-4ff1-9832-b90e8c024644"
      },
      "source": [
        "for name, param in net.named_parameters():\n",
        "  print(name,param.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.filts False\n",
            "conv2.filts False\n",
            "conv3.filts False\n",
            "fc1.weight True\n",
            "fc1.bias True\n",
            "fc2.weight True\n",
            "fc2.bias True\n",
            "fc3.weight True\n",
            "fc3.bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2G2mtPaQ9tN"
      },
      "source": [
        "# 5 load the teacher model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFp5X6irl5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15764d40-d2ff-4129-fcba-2ad016f73f09"
      },
      "source": [
        "model = torch.load(BASE_PATH +\"/teacher.pkl\")\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (fc1): Linear(in_features=9216, out_features=1024, bias=True)\n",
              "    (relu1): ReLU()\n",
              "    (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    (relu2): ReLU()\n",
              "    (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
              "    (output): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros([10,3,224,224])\n",
        "print(x.shape)\n",
        "model.features[0:11](x.cuda()).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGBKRTf4xhOt",
        "outputId": "cf0117f4-148e-4756-f820-ed845304697c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 256, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5sz3ewhroVo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "115a017f-6711-4e1b-9369-1b86e48ac749"
      },
      "source": [
        "_, test_accuracy = getLossAccuracyOnDataset(model, testloader, \"cuda\")\n",
        "print('teacher test accuracy (w distillation): ', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "teacher test accuracy (w distillation):  0.939572192513369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oiak52H9RAcu"
      },
      "source": [
        "# 6 knowledge distillation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3CsAFqbql32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "607c9a2a-1127-4e34-9322-5efdc75220ca"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import argparse\n",
        "import time\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "    \n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "num_epochs = 50\n",
        "print_every = 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WmOu3lTrvvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e42468c4-7e59-4fea-e737-c6ad48c37e81"
      },
      "source": [
        "temperatures = [10]\n",
        "# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n",
        "# loss = alpha * st + (1 - alpha) * tt\n",
        "alphas = [0.5]\n",
        "learning_rates = [0.0001]\n",
        "learning_rate_decays = [0.95]\n",
        "weight_decays = [1e-5]\n",
        "momentums = [0.9]\n",
        "dropout_probabilities = [(0,0)]\n",
        "hparams_list = []\n",
        "for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n",
        "                                        momentums, learning_rates):\n",
        "    hparam = {}\n",
        "    hparam['alpha'] = hparam_tuple[0]\n",
        "    hparam['T'] = hparam_tuple[1]\n",
        "    hparam['dropout_input'] = hparam_tuple[2][0]\n",
        "    hparam['dropout_hidden'] = hparam_tuple[2][1]\n",
        "    hparam['weight_decay'] = hparam_tuple[3]\n",
        "    hparam['lr_decay'] = hparam_tuple[4]\n",
        "    hparam['momentum'] = hparam_tuple[5]\n",
        "    hparam['lr'] = hparam_tuple[6]\n",
        "    hparams_list.append(hparam)\n",
        "print(hparams_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'alpha': 0.5, 'T': 10, 'dropout_input': 0, 'dropout_hidden': 0, 'weight_decay': 1e-05, 'lr_decay': 0.95, 'momentum': 0.9, 'lr': 0.0001}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_j71Slhrz_k"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "use_gpu = True\n",
        "# Ensure reproducibility\n",
        "def reproducibilitySeed():\n",
        "    \"\"\"\n",
        "    Ensure reproducibility of results; Seeds to 0\n",
        "    \"\"\"\n",
        "    torch_init_seed = 0\n",
        "    torch.manual_seed(torch_init_seed)\n",
        "    numpy_init_seed = 0\n",
        "    np.random.seed(numpy_init_seed)\n",
        "    if use_gpu:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "reproducibilitySeed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHdc9mqDr3F5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e9f691c-172b-4f54-8494-94333d1c9899"
      },
      "source": [
        "model.to(device)\n",
        "results_distill = {}\n",
        "\n",
        "for hparam in hparams_list:\n",
        "    print('Training with hparams' + hparamToString(hparam))\n",
        "    reproducibilitySeed()\n",
        "    student_net = student_net\n",
        "    hparam_tuple = hparamDictToTuple(hparam)\n",
        "    results_distill[hparam_tuple] = trainStudentOnHparam(model, student_net, hparam, num_epochs, \n",
        "                                                                trainloader, testloader, \n",
        "                                                                print_every=print_every, \n",
        "                                                                fast_device = device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with hparamsT=10, alpha=0.5, dropout_hidden=0, dropout_input=0, lr=0.0001, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 validation accuracy: 0.780\n",
            "[1,   200/  625] train loss: 2.211 train accuracy: 0.688\n",
            "[1,   400/  625] train loss: 0.879 train accuracy: 0.812\n",
            "[1,   600/  625] train loss: 1.973 train accuracy: 0.688\n",
            "epoch: 1 validation accuracy: 0.788\n",
            "[2,   200/  625] train loss: 1.973 train accuracy: 0.938\n",
            "[2,   400/  625] train loss: 3.238 train accuracy: 0.750\n",
            "[2,   600/  625] train loss: 2.112 train accuracy: 0.875\n",
            "epoch: 2 validation accuracy: 0.787\n",
            "[3,   200/  625] train loss: 1.870 train accuracy: 0.938\n",
            "[3,   400/  625] train loss: 3.349 train accuracy: 1.000\n",
            "[3,   600/  625] train loss: 2.072 train accuracy: 0.875\n",
            "epoch: 3 validation accuracy: 0.789\n",
            "[4,   200/  625] train loss: 4.293 train accuracy: 0.875\n",
            "[4,   400/  625] train loss: 3.130 train accuracy: 0.750\n",
            "[4,   600/  625] train loss: 1.857 train accuracy: 0.688\n",
            "epoch: 4 validation accuracy: 0.787\n",
            "[5,   200/  625] train loss: 3.130 train accuracy: 0.750\n",
            "[5,   400/  625] train loss: 1.783 train accuracy: 0.750\n",
            "[5,   600/  625] train loss: 2.141 train accuracy: 0.812\n",
            "epoch: 5 validation accuracy: 0.791\n",
            "[6,   200/  625] train loss: 1.527 train accuracy: 0.938\n",
            "[6,   400/  625] train loss: 1.504 train accuracy: 0.875\n",
            "[6,   600/  625] train loss: 2.429 train accuracy: 0.875\n",
            "epoch: 6 validation accuracy: 0.796\n",
            "[7,   200/  625] train loss: 3.008 train accuracy: 0.625\n",
            "[7,   400/  625] train loss: 2.243 train accuracy: 0.938\n",
            "[7,   600/  625] train loss: 1.504 train accuracy: 0.875\n",
            "epoch: 7 validation accuracy: 0.796\n",
            "[8,   200/  625] train loss: 2.502 train accuracy: 0.750\n",
            "[8,   400/  625] train loss: 2.068 train accuracy: 0.875\n",
            "[8,   600/  625] train loss: 1.052 train accuracy: 0.938\n",
            "epoch: 8 validation accuracy: 0.795\n",
            "[9,   200/  625] train loss: 2.097 train accuracy: 0.812\n",
            "[9,   400/  625] train loss: 2.879 train accuracy: 0.812\n",
            "[9,   600/  625] train loss: 2.787 train accuracy: 0.812\n",
            "epoch: 9 validation accuracy: 0.796\n",
            "[10,   200/  625] train loss: 1.678 train accuracy: 0.812\n",
            "[10,   400/  625] train loss: 2.261 train accuracy: 0.750\n",
            "[10,   600/  625] train loss: 2.070 train accuracy: 0.875\n",
            "epoch: 10 validation accuracy: 0.797\n",
            "[11,   200/  625] train loss: 2.810 train accuracy: 0.938\n",
            "[11,   400/  625] train loss: 3.983 train accuracy: 0.875\n",
            "[11,   600/  625] train loss: 1.252 train accuracy: 0.875\n",
            "epoch: 11 validation accuracy: 0.799\n",
            "[12,   200/  625] train loss: 1.060 train accuracy: 1.000\n",
            "[12,   400/  625] train loss: 1.544 train accuracy: 0.625\n",
            "[12,   600/  625] train loss: 2.006 train accuracy: 0.812\n",
            "epoch: 12 validation accuracy: 0.797\n",
            "[13,   200/  625] train loss: 2.085 train accuracy: 0.812\n",
            "[13,   400/  625] train loss: 2.279 train accuracy: 1.000\n",
            "[13,   600/  625] train loss: 5.042 train accuracy: 0.750\n",
            "epoch: 13 validation accuracy: 0.795\n",
            "[14,   200/  625] train loss: 1.378 train accuracy: 0.812\n",
            "[14,   400/  625] train loss: 1.355 train accuracy: 0.875\n",
            "[14,   600/  625] train loss: 2.212 train accuracy: 0.812\n",
            "epoch: 14 validation accuracy: 0.798\n",
            "[15,   200/  625] train loss: 2.214 train accuracy: 0.812\n",
            "[15,   400/  625] train loss: 1.935 train accuracy: 0.875\n",
            "[15,   600/  625] train loss: 2.027 train accuracy: 0.875\n",
            "epoch: 15 validation accuracy: 0.797\n",
            "[16,   200/  625] train loss: 2.287 train accuracy: 0.875\n",
            "[16,   400/  625] train loss: 1.076 train accuracy: 0.938\n",
            "[16,   600/  625] train loss: 2.042 train accuracy: 0.938\n",
            "epoch: 16 validation accuracy: 0.795\n",
            "[17,   200/  625] train loss: 3.343 train accuracy: 0.812\n",
            "[17,   400/  625] train loss: 2.409 train accuracy: 0.750\n",
            "[17,   600/  625] train loss: 1.842 train accuracy: 0.812\n",
            "epoch: 17 validation accuracy: 0.796\n",
            "[18,   200/  625] train loss: 1.328 train accuracy: 0.875\n",
            "[18,   400/  625] train loss: 1.821 train accuracy: 0.812\n",
            "[18,   600/  625] train loss: 1.671 train accuracy: 0.875\n",
            "epoch: 18 validation accuracy: 0.795\n",
            "[19,   200/  625] train loss: 2.127 train accuracy: 0.938\n",
            "[19,   400/  625] train loss: 2.965 train accuracy: 0.625\n",
            "[19,   600/  625] train loss: 1.849 train accuracy: 0.688\n",
            "epoch: 19 validation accuracy: 0.798\n",
            "[20,   200/  625] train loss: 1.677 train accuracy: 0.812\n",
            "[20,   400/  625] train loss: 1.681 train accuracy: 0.938\n",
            "[20,   600/  625] train loss: 1.925 train accuracy: 0.875\n",
            "epoch: 20 validation accuracy: 0.793\n",
            "[21,   200/  625] train loss: 2.443 train accuracy: 0.812\n",
            "[21,   400/  625] train loss: 1.518 train accuracy: 0.875\n",
            "[21,   600/  625] train loss: 2.301 train accuracy: 0.688\n",
            "epoch: 21 validation accuracy: 0.799\n",
            "[22,   200/  625] train loss: 1.791 train accuracy: 0.812\n",
            "[22,   400/  625] train loss: 1.806 train accuracy: 0.812\n",
            "[22,   600/  625] train loss: 1.231 train accuracy: 0.875\n",
            "epoch: 22 validation accuracy: 0.797\n",
            "[23,   200/  625] train loss: 2.716 train accuracy: 0.812\n",
            "[23,   400/  625] train loss: 2.250 train accuracy: 1.000\n",
            "[23,   600/  625] train loss: 4.268 train accuracy: 0.938\n",
            "epoch: 23 validation accuracy: 0.798\n",
            "[24,   200/  625] train loss: 2.374 train accuracy: 0.625\n",
            "[24,   400/  625] train loss: 3.208 train accuracy: 0.875\n",
            "[24,   600/  625] train loss: 1.654 train accuracy: 0.875\n",
            "epoch: 24 validation accuracy: 0.801\n",
            "[25,   200/  625] train loss: 2.743 train accuracy: 0.812\n",
            "[25,   400/  625] train loss: 1.449 train accuracy: 1.000\n",
            "[25,   600/  625] train loss: 1.688 train accuracy: 0.875\n",
            "epoch: 25 validation accuracy: 0.799\n",
            "[26,   200/  625] train loss: 1.845 train accuracy: 0.812\n",
            "[26,   400/  625] train loss: 3.207 train accuracy: 0.625\n",
            "[26,   600/  625] train loss: 1.301 train accuracy: 0.938\n",
            "epoch: 26 validation accuracy: 0.799\n",
            "[27,   200/  625] train loss: 1.793 train accuracy: 0.688\n",
            "[27,   400/  625] train loss: 2.098 train accuracy: 0.750\n",
            "[27,   600/  625] train loss: 1.784 train accuracy: 0.750\n",
            "epoch: 27 validation accuracy: 0.799\n",
            "[28,   200/  625] train loss: 1.446 train accuracy: 0.875\n",
            "[28,   400/  625] train loss: 2.396 train accuracy: 0.875\n",
            "[28,   600/  625] train loss: 1.231 train accuracy: 0.875\n",
            "epoch: 28 validation accuracy: 0.798\n",
            "[29,   200/  625] train loss: 1.613 train accuracy: 0.812\n",
            "[29,   400/  625] train loss: 1.273 train accuracy: 0.938\n",
            "[29,   600/  625] train loss: 0.835 train accuracy: 0.938\n",
            "epoch: 29 validation accuracy: 0.801\n",
            "[30,   200/  625] train loss: 1.590 train accuracy: 0.812\n",
            "[30,   400/  625] train loss: 1.865 train accuracy: 0.750\n",
            "[30,   600/  625] train loss: 2.096 train accuracy: 0.875\n",
            "epoch: 30 validation accuracy: 0.800\n",
            "[31,   200/  625] train loss: 1.730 train accuracy: 0.875\n",
            "[31,   400/  625] train loss: 2.030 train accuracy: 0.875\n",
            "[31,   600/  625] train loss: 1.641 train accuracy: 0.750\n",
            "epoch: 31 validation accuracy: 0.801\n",
            "[32,   200/  625] train loss: 2.153 train accuracy: 0.938\n",
            "[32,   400/  625] train loss: 1.673 train accuracy: 0.938\n",
            "[32,   600/  625] train loss: 1.132 train accuracy: 0.812\n",
            "epoch: 32 validation accuracy: 0.801\n",
            "[33,   200/  625] train loss: 2.851 train accuracy: 0.938\n",
            "[33,   400/  625] train loss: 2.136 train accuracy: 1.000\n",
            "[33,   600/  625] train loss: 1.477 train accuracy: 0.750\n",
            "epoch: 33 validation accuracy: 0.799\n",
            "[34,   200/  625] train loss: 0.954 train accuracy: 0.938\n",
            "[34,   400/  625] train loss: 1.297 train accuracy: 1.000\n",
            "[34,   600/  625] train loss: 1.708 train accuracy: 0.812\n",
            "epoch: 34 validation accuracy: 0.799\n",
            "[35,   200/  625] train loss: 2.052 train accuracy: 0.812\n",
            "[35,   400/  625] train loss: 2.474 train accuracy: 0.875\n",
            "[35,   600/  625] train loss: 1.647 train accuracy: 0.688\n",
            "epoch: 35 validation accuracy: 0.799\n",
            "[36,   200/  625] train loss: 2.474 train accuracy: 0.812\n",
            "[36,   400/  625] train loss: 2.125 train accuracy: 0.812\n",
            "[36,   600/  625] train loss: 1.895 train accuracy: 0.875\n",
            "epoch: 36 validation accuracy: 0.799\n",
            "[37,   200/  625] train loss: 1.755 train accuracy: 0.812\n",
            "[37,   400/  625] train loss: 2.737 train accuracy: 0.625\n",
            "[37,   600/  625] train loss: 2.357 train accuracy: 0.875\n",
            "epoch: 37 validation accuracy: 0.799\n",
            "[38,   200/  625] train loss: 4.116 train accuracy: 0.750\n",
            "[38,   400/  625] train loss: 2.059 train accuracy: 0.625\n",
            "[38,   600/  625] train loss: 3.236 train accuracy: 1.000\n",
            "epoch: 38 validation accuracy: 0.801\n",
            "[39,   200/  625] train loss: 1.068 train accuracy: 0.750\n",
            "[39,   400/  625] train loss: 2.222 train accuracy: 0.875\n",
            "[39,   600/  625] train loss: 2.276 train accuracy: 0.875\n",
            "epoch: 39 validation accuracy: 0.801\n",
            "[40,   200/  625] train loss: 1.978 train accuracy: 0.750\n",
            "[40,   400/  625] train loss: 1.223 train accuracy: 0.938\n",
            "[40,   600/  625] train loss: 2.586 train accuracy: 0.875\n",
            "epoch: 40 validation accuracy: 0.801\n",
            "[41,   200/  625] train loss: 1.533 train accuracy: 0.875\n",
            "[41,   400/  625] train loss: 1.925 train accuracy: 0.812\n",
            "[41,   600/  625] train loss: 1.172 train accuracy: 0.938\n",
            "epoch: 41 validation accuracy: 0.799\n",
            "[42,   200/  625] train loss: 0.836 train accuracy: 0.750\n",
            "[42,   400/  625] train loss: 1.323 train accuracy: 0.938\n",
            "[42,   600/  625] train loss: 1.863 train accuracy: 0.938\n",
            "epoch: 42 validation accuracy: 0.799\n",
            "[43,   200/  625] train loss: 2.547 train accuracy: 0.875\n",
            "[43,   400/  625] train loss: 1.983 train accuracy: 0.875\n",
            "[43,   600/  625] train loss: 1.745 train accuracy: 0.875\n",
            "epoch: 43 validation accuracy: 0.801\n",
            "[44,   200/  625] train loss: 2.363 train accuracy: 0.812\n",
            "[44,   400/  625] train loss: 2.365 train accuracy: 0.812\n",
            "[44,   600/  625] train loss: 2.637 train accuracy: 0.750\n",
            "epoch: 44 validation accuracy: 0.799\n",
            "[45,   200/  625] train loss: 3.302 train accuracy: 0.688\n",
            "[45,   400/  625] train loss: 1.879 train accuracy: 0.875\n",
            "[45,   600/  625] train loss: 1.945 train accuracy: 0.875\n",
            "epoch: 45 validation accuracy: 0.799\n",
            "[46,   200/  625] train loss: 1.979 train accuracy: 0.938\n",
            "[46,   400/  625] train loss: 2.021 train accuracy: 0.688\n",
            "[46,   600/  625] train loss: 1.812 train accuracy: 0.875\n",
            "epoch: 46 validation accuracy: 0.799\n",
            "[47,   200/  625] train loss: 1.427 train accuracy: 0.938\n",
            "[47,   400/  625] train loss: 1.930 train accuracy: 0.812\n",
            "[47,   600/  625] train loss: 1.150 train accuracy: 0.938\n",
            "epoch: 47 validation accuracy: 0.799\n",
            "[48,   200/  625] train loss: 2.340 train accuracy: 0.875\n",
            "[48,   400/  625] train loss: 1.421 train accuracy: 0.875\n",
            "[48,   600/  625] train loss: 1.812 train accuracy: 0.875\n",
            "epoch: 48 validation accuracy: 0.798\n",
            "[49,   200/  625] train loss: 1.582 train accuracy: 0.875\n",
            "[49,   400/  625] train loss: 4.728 train accuracy: 0.750\n",
            "[49,   600/  625] train loss: 1.568 train accuracy: 0.938\n",
            "epoch: 49 validation accuracy: 0.800\n",
            "[50,   200/  625] train loss: 2.009 train accuracy: 0.875\n",
            "[50,   400/  625] train loss: 0.954 train accuracy: 0.938\n",
            "[50,   600/  625] train loss: 1.082 train accuracy: 0.875\n",
            "epoch: 50 validation accuracy: 0.798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeZJvrXxKPxo"
      },
      "source": [
        "torch.save(student_net.state_dict(), BASE_PATH+'/net_params_new.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6zxx1byKw0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9340d311-a02a-4597-a546-a3eb9b685ae9"
      },
      "source": [
        "_, test_accuracy = getLossAccuracyOnDataset(student_net, testloader, device)\n",
        "print('teacher test accuracy (w distillation): ', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "teacher test accuracy (w distillation):  0.7983957219251336\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}